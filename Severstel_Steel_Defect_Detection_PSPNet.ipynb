{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "name": "Severstel Steel Defect Detection-PSPNet.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v6gY-DtlNg5V",
        "colab_type": "text"
      },
      "source": [
        "# Severstel Steel Defect Detection"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jAb_wAJ5TvxU",
        "colab_type": "code",
        "outputId": "0bc4a2ab-67af-4000-e70c-9166c6c3bbc4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        }
      },
      "source": [
        "!pip3 install --user kaggle --upgrade"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting kaggle\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/62/ab/bb20f9b9e24f9a6250f95a432f8d9a7d745f8d24039d7a5a6eaadb7783ba/kaggle-1.5.6.tar.gz (58kB)\n",
            "\r\u001b[K     |█████▋                          | 10kB 26.2MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 20kB 6.0MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 30kB 8.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 40kB 5.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 51kB 6.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 61kB 7.2MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.10 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.12.0)\n",
            "Requirement already satisfied, skipping upgrade: certifi in /usr/local/lib/python3.6/dist-packages (from kaggle) (2019.6.16)\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.5.3)\n",
            "Requirement already satisfied, skipping upgrade: requests in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.21.0)\n",
            "Requirement already satisfied, skipping upgrade: tqdm in /usr/local/lib/python3.6/dist-packages (from kaggle) (4.28.1)\n",
            "Requirement already satisfied, skipping upgrade: python-slugify in /usr/local/lib/python3.6/dist-packages (from kaggle) (3.0.3)\n",
            "Requirement already satisfied, skipping upgrade: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (2.8)\n",
            "Requirement already satisfied, skipping upgrade: text-unidecode==1.2 in /usr/local/lib/python3.6/dist-packages (from python-slugify->kaggle) (1.2)\n",
            "Building wheels for collected packages: kaggle\n",
            "  Building wheel for kaggle (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for kaggle: filename=kaggle-1.5.6-cp36-none-any.whl size=72859 sha256=aef43e89029694351c549d3c13b5875bbe84ddc4d00413cff16071a9e285a059\n",
            "  Stored in directory: /root/.cache/pip/wheels/57/4e/e8/bb28d035162fb8f17f8ca5d42c3230e284c6aa565b42b72674\n",
            "Successfully built kaggle\n",
            "Installing collected packages: kaggle\n",
            "\u001b[33m  WARNING: The script kaggle is installed in '/root/.local/bin' which is not on PATH.\n",
            "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
            "Successfully installed kaggle-1.5.6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dXdzjo2WT0ny",
        "colab_type": "code",
        "outputId": "90ef304d-cb09-4746-fe6a-0f0813590148",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": "OK"
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 94
        }
      },
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-525592b8-d7d4-4800-a32e-b6f45a140bdf\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-525592b8-d7d4-4800-a32e-b6f45a140bdf\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'kaggle.json': b'{\"username\":\"kiranscaria\",\"key\":\"3d0516c994f8dc33547e7083a17b1e5e\"}'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mrqf-NbdT11u",
        "colab_type": "code",
        "outputId": "097ebb11-1efd-4c25-cdc6-8755267a49a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "!ls ~/.kaggle"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "kaggle.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h56KbyHwUDgO",
        "colab_type": "code",
        "outputId": "10d88e2b-de96-4b33-b316-80ce731f8d65",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        }
      },
      "source": [
        "!kaggle competitions download -c severstal-steel-defect-detection"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.6 / client 1.5.4)\n",
            "Downloading train.csv.zip to /content\n",
            " 72% 5.00M/6.91M [00:00<00:00, 19.7MB/s]\n",
            "100% 6.91M/6.91M [00:00<00:00, 23.0MB/s]\n",
            "Downloading sample_submission.csv to /content\n",
            "  0% 0.00/141k [00:00<?, ?B/s]\n",
            "100% 141k/141k [00:00<00:00, 147MB/s]\n",
            "Downloading train_images.zip to /content\n",
            "100% 1.16G/1.16G [00:16<00:00, 74.1MB/s]\n",
            "100% 1.16G/1.16G [00:16<00:00, 77.8MB/s]\n",
            "Downloading test_images.zip to /content\n",
            " 92% 119M/129M [00:01<00:00, 66.9MB/s] \n",
            "100% 129M/129M [00:01<00:00, 86.2MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MSJITKebXdOd",
        "colab_type": "code",
        "outputId": "85ea93b2-6df2-4c71-a2ae-ed2a588f4bb6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "source": [
        "!mkdir data\n",
        "!mkdir data/train_images\n",
        "!mkdir data/test-images\n",
        "!mv -v *.zip data/\n",
        "!mv -v *.csv data/"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "renamed 'test_images.zip' -> 'data/test_images.zip'\n",
            "renamed 'train.csv.zip' -> 'data/train.csv.zip'\n",
            "renamed 'train_images.zip' -> 'data/train_images.zip'\n",
            "renamed 'sample_submission.csv' -> 'data/sample_submission.csv'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PO3bLy1JUKii",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%capture\n",
        "!unzip data/train.csv.zip -d data/\n",
        "!unzip data/train_images.zip -d data/train_images/\n",
        "!unzip data/test_images.zip -d data/test_images/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "vUAEoWUUNg5i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import cv2\n",
        "import time\n",
        "import math\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.nn import BatchNorm2d\n",
        "from torch.nn import functional as F\n",
        "from torchvision import transforms, models\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "from torchvision.transforms import functional as Ftrans"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jOzuEX-kNg56",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "seed = 42\n",
        "batch_size = 4\n",
        "num_epochs = 20\n",
        "test_percent = 0.20\n",
        "learning_rate = 3e-4\n",
        "# Accumulates gradient of four mini-batches\n",
        "# Effectively making the batch_size equal to accumulation_steps*times the batch_size\n",
        "accumulation_steps = 4   \n",
        "\n",
        "num_workers = 4\n",
        "\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "torch.cuda.manual_seed(seed)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "data_folder = 'data/train_images'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "87-aZTjRQyyz",
        "colab_type": "text"
      },
      "source": [
        "## Download Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x4iBFjkMNg6K",
        "colab_type": "text"
      },
      "source": [
        "## RLE-Mask utility functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Czznd8YbNg6Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#https://www.kaggle.com/paulorzp/rle-functions-run-lenght-encode-decode\n",
        "def mask2rle(img):\n",
        "    '''\n",
        "    img: numpy array, 1 -> mask, 0 -> background\n",
        "    Returns run length as string formated\n",
        "    '''\n",
        "    pixels= img.T.flatten()\n",
        "    pixels = np.concatenate([[0], pixels, [0]])\n",
        "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
        "    runs[1::2] -= runs[::2]\n",
        "    return ' '.join(str(x) for x in runs)\n",
        "\n",
        "def make_mask(row_id, df):\n",
        "    '''Given a row index, return image_id and mask (256, 1600, 4) from the dataframe `df`'''\n",
        "    fname = df.iloc[row_id].name\n",
        "    labels = df.iloc[row_id][:4]\n",
        "    masks = np.zeros((256, 1600, 4), dtype=np.float32) # float32 is V.Imp\n",
        "    # 4:class 1～4 (ch:0～3)\n",
        "    ## TODO: REMOVE\n",
        "    print(f'In make_mask function.\\nLabels: {labels}\\tFname: {fname}\\nRow: {df.iloc[row_id]}')\n",
        "    ##\n",
        "    for idx, label in enumerate(labels.values):\n",
        "        if label is not np.nan:\n",
        "            label = label.split(\" \")\n",
        "            positions = map(int, label[0::2])\n",
        "            length = map(int, label[1::2])\n",
        "            mask = np.zeros(256 * 1600, dtype=np.uint8)\n",
        "            for pos, le in zip(positions, length):\n",
        "                mask[pos:(pos + le)] = 1\n",
        "            masks[:, :, idx] = mask.reshape(256, 1600, order='F')\n",
        "    return fname, masks"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PfhYt9jpNg6g",
        "colab_type": "text"
      },
      "source": [
        "## Dataloader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BtKnuuC0Ng6k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SteelDataset(Dataset):\n",
        "    def __init__(self, df, data_folder, mean, std, phase):\n",
        "        self.df = df\n",
        "        self.phase = phase\n",
        "        self.root = data_folder\n",
        "        self.fnames = self.df.index.tolist()\n",
        "        \n",
        "        # normalize\n",
        "        self.normalize = transforms.Normalize(mean=mean, std=std)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image_id, mask = make_mask(idx, self.df)\n",
        "        image_path = os.path.join(self.root, \"train_images\",  image_id)\n",
        "        img = cv2.imread(image_path)\n",
        "        img, mask = self.transform(phase, img=img, mask=mask)\n",
        "        print(mask.shape, img.shape)\n",
        "        return img, mask\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.fnames)\n",
        "\n",
        "    def transform(self, phase, img, mask):\n",
        "        # To PIL Image\n",
        "        img = Ftrans.to_pil_image(img)\n",
        "        mask = Ftrans.to_pil_image(np.uint8(mask))\n",
        "\n",
        "        # Resize\n",
        "        resize = transforms.Resize(size=(256, 256))\n",
        "        img = resize(img)\n",
        "        mask = resize(mask)\n",
        "\n",
        "        if phase=='train':\n",
        "            # # Random Crop\n",
        "            if random.random() > 0.50:\n",
        "                i, j, h, w = transforms.RandomCrop.get_params(img, output_size=(256, 256))\n",
        "                img = Ftrans.crop(img, i, j, h, w)\n",
        "                mask = Ftrans.crop(mask ,i, j, h, w)\n",
        "\n",
        "            # # Random Horizontal Flipping\n",
        "            if random.random() > 0.50:\n",
        "                img = Ftrans.hflip(img)\n",
        "                mask = Ftrans.hflip(mask)\n",
        "\n",
        "            # # Random Vertical Flipping\n",
        "            if random.random() > 0.50:\n",
        "                img = Ftrans.vflip(img)\n",
        "                mask = Ftrans.vflip(mask)\n",
        "\n",
        "        # # To tensor\n",
        "        img = Ftrans.to_tensor(img)\n",
        "        mask = Ftrans.to_tensor(mask)\n",
        "\n",
        "        # # Normalize\n",
        "        img = self.normalize(img)\n",
        "        \n",
        "        return img, mask\n",
        "\n",
        "def provider(data_folder, df_path, phase, mean=None, std=None, batch_size=8, num_workers=4):\n",
        "    '''Returns dataloader for the model training'''\n",
        "    df = pd.read_csv(df_path)\n",
        "    # https://www.kaggle.com/amanooo/defect-detection-starter-u-net\n",
        "    df['ImageId'], df['ClassId'] = zip(*df['ImageId_ClassId'].str.split('_'))\n",
        "    df['ClassId'] = df['ClassId'].astype(int)\n",
        "    df = df.pivot(index='ImageId',columns='ClassId',values='EncodedPixels')\n",
        "    df['defects'] = df.count(axis=1)\n",
        "    \n",
        "    train_df, val_df = train_test_split(df, test_size=test_percent, stratify=df[\"defects\"], random_state=seed)\n",
        "    df = train_df if phase == \"train\" else val_df\n",
        "    image_dataset = SteelDataset(df, data_folder, mean, std, phase)\n",
        "    dataloader = DataLoader(image_dataset, batch_size=batch_size, num_workers=num_workers, pin_memory=True, shuffle=True)\n",
        "\n",
        "    return dataloader"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l1WNzJEXNg6z",
        "colab_type": "text"
      },
      "source": [
        "## Metrics: IoU and Dice "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "96bpSpDANg63",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def metric(probability, truth, threshold=0.5, reduction='none'):\n",
        "    '''Calculates dice of positive and negative images seperately'''\n",
        "    '''probability and truth must be torch tensors'''\n",
        "    batch_size = len(truth)\n",
        "    with torch.no_grad():\n",
        "        probability = probability.view(batch_size, -1)\n",
        "        truth = truth.view(batch_size, -1)\n",
        "        assert(probability.shape == truth.shape)\n",
        "\n",
        "        p = (probability > threshold).float()\n",
        "        t = (truth > 0.5).float()\n",
        "\n",
        "        t_sum = t.sum(-1)\n",
        "        p_sum = p.sum(-1)\n",
        "        neg_index = torch.nonzero(t_sum == 0)\n",
        "        pos_index = torch.nonzero(t_sum >= 1)\n",
        "\n",
        "        dice_neg = (p_sum == 0).float()\n",
        "        dice_pos = 2 * (p*t).sum(-1)/((p+t).sum(-1))\n",
        "\n",
        "        dice_neg = dice_neg[neg_index]\n",
        "        dice_pos = dice_pos[pos_index]\n",
        "        dice = torch.cat([dice_pos, dice_neg])\n",
        "\n",
        "        dice_neg = np.nan_to_num(dice_neg.mean().item(), 0)\n",
        "        dice_pos = np.nan_to_num(dice_pos.mean().item(), 0)\n",
        "        dice = dice.mean().item()\n",
        "\n",
        "        num_neg = len(neg_index)\n",
        "        num_pos = len(pos_index)\n",
        "\n",
        "    return dice, dice_neg, dice_pos, num_neg, num_pos\n",
        "\n",
        "\n",
        "def compute_ious(pred, label, classes, ignore_index=255, only_present=True):\n",
        "    '''computes iou for one ground truth mask and predicted mask'''\n",
        "    pred[label == ignore_index] = 0\n",
        "    ious = []\n",
        "    for c in classes:\n",
        "        label_c = label == c\n",
        "        if only_present and np.sum(label_c) == 0:\n",
        "            ious.append(np.nan)\n",
        "            continue\n",
        "        pred_c = pred == c\n",
        "        intersection = np.logical_and(pred_c, label_c).sum()\n",
        "        union = np.logical_or(pred_c, label_c).sum()\n",
        "        if union != 0:\n",
        "            ious.append(intersection / union)\n",
        "    return ious if ious else [1]\n",
        "\n",
        "\n",
        "def compute_iou_batch(outputs, labels, classes=None):\n",
        "    '''computes mean iou for a batch of ground truth masks and predicted masks'''\n",
        "    ious = []\n",
        "    preds = np.copy(outputs) # copy is imp\n",
        "    labels = np.array(labels) # tensor to np\n",
        "    for pred, label in zip(preds, labels):\n",
        "        ious.append(np.nanmean(compute_ious(pred, label, classes)))\n",
        "    iou = np.nanmean(ious)\n",
        "    return iou\n",
        "\n",
        "class Meter:\n",
        "    '''A meter to keep track of iou and dice scores throughout an epoch'''\n",
        "    def __init__(self, phase, epoch):\n",
        "        self.base_threshold = 0.5 # <<<<<<<<<<< here's the threshold\n",
        "        self.base_dice_scores = []\n",
        "        self.dice_neg_scores = []\n",
        "        self.dice_pos_scores = []\n",
        "        self.iou_scores = []\n",
        "\n",
        "    def update(self, targets, outputs):\n",
        "        probs = torch.sigmoid(outputs)\n",
        "        dice, dice_neg, dice_pos, _, _ = metric(probs, targets, self.base_threshold)\n",
        "        self.base_dice_scores.append(dice)\n",
        "        self.dice_pos_scores.append(dice_pos)\n",
        "        self.dice_neg_scores.append(dice_neg)\n",
        "        preds = predict(probs, self.base_threshold)\n",
        "        iou = compute_iou_batch(preds, targets, classes=[1])\n",
        "        self.iou_scores.append(iou)\n",
        "\n",
        "    def get_metrics(self):\n",
        "        dice = np.mean(self.base_dice_scores)\n",
        "        dice_neg = np.mean(self.dice_neg_scores)\n",
        "        dice_pos = np.mean(self.dice_pos_scores)\n",
        "        dices = [dice, dice_neg, dice_pos]\n",
        "        iou = np.nanmean(self.iou_scores)\n",
        "        return dices, iou"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aYmUOEmnNg7O",
        "colab_type": "text"
      },
      "source": [
        "## Logger Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KJZevu2LNg7W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def epoch_log(phase, epoch, epoch_loss, meter, start):\n",
        "    '''logging the metrics at the end of an epoch'''\n",
        "    dices, iou = meter.get_metrics()\n",
        "    dice, dice_neg, dice_pos = dices\n",
        "    print(\"Loss: %0.4f | IoU: %0.4f | dice: %0.4f | dice_neg: %0.4f | dice_pos: %0.4f\" % (epoch_loss, iou, dice, dice_neg, dice_pos))\n",
        "    return dice, iou"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gonsjMtiNg7j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict(X, threshold):\n",
        "    '''X is sigmoid output of the model'''\n",
        "    X_p = np.copy(X)\n",
        "    preds = (X_p > threshold).astype('uint8')\n",
        "    return preds"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6uEjDsRsNg7u",
        "colab_type": "text"
      },
      "source": [
        "## Load the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8adpXKmtNg7y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "phases = [\"train\", \"val\"]\n",
        "dataloaders = {phase: provider(data_folder='data', df_path='data/train.csv', phase=phase,\n",
        "                               mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225), \n",
        "                               batch_size=batch_size, num_workers=num_workers) for phase in phases}\n",
        "losses = {phase: [] for phase in phases}\n",
        "iou_scores = {phase: [] for phase in phases}\n",
        "dice_scores = {phase: [] for phase in phases}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LZdvR7ZgNg8B",
        "colab_type": "text"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VVd-KxmTXusH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "try:\n",
        "    from urllib import urlretrieve\n",
        "except ImportError:\n",
        "    from urllib.request import urlretrieve\n",
        "\n",
        "def load_url(url, model_dir='./pretrained', map_location=None):\n",
        "    if not os.path.exists(model_dir):\n",
        "        os.makedirs(model_dir)\n",
        "    filename = url.split('/')[-1]\n",
        "    cached_file = os.path.join(model_dir, filename)\n",
        "    if not os.path.exists(cached_file):\n",
        "        sys.stderr.write('Downloading: \"{}\" to {}\\n'.format(url, cached_file))\n",
        "        urlretrieve(url, cached_file)\n",
        "    return torch.load(cached_file, map_location=map_location)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "__70891qqTIr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class PSPModule(nn.Module):\n",
        "    def __init__(self, features, out_features=1024, sizes=(1, 2, 3, 6)):\n",
        "        super().__init__()\n",
        "        self.stages = []\n",
        "        self.stages = nn.ModuleList([self._make_stage(features, size) for size in sizes])\n",
        "        self.bottleneck = nn.Conv2d(features * (len(sizes) + 1), out_features, kernel_size=1)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def _make_stage(self, features, size):\n",
        "        prior = nn.AdaptiveAvgPool2d(output_size=(size, size))\n",
        "        conv = nn.Conv2d(features, features, kernel_size=1, bias=False)\n",
        "        return nn.Sequential(prior, conv)\n",
        "\n",
        "    def forward(self, feats):\n",
        "        h, w = feats.size(2), feats.size(3)\n",
        "        priors = [F.upsample(input=stage(feats), size=(h, w), mode='bilinear') for stage in self.stages] + [feats]\n",
        "        bottle = self.bottleneck(torch.cat(priors, 1))\n",
        "        return self.relu(bottle)\n",
        "\n",
        "\n",
        "class PSPUpsample(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, 3, padding=1),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.PReLU()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        h, w = 2 * x.size(2), 2 * x.size(3)\n",
        "        p = F.upsample(input=x, size=(h, w), mode='bilinear')\n",
        "        return self.conv(p)\n",
        "\n",
        "\n",
        "class PSPNet(nn.Module):\n",
        "    def __init__(self, n_classes=18, sizes=(1, 2, 3, 6), psp_size=2048, deep_features_size=1024, backend='resnet34',\n",
        "                 pretrained=True):\n",
        "        super().__init__()\n",
        "        self.feats = getattr(extractors, backend)(pretrained)\n",
        "        self.psp = PSPModule(psp_size, 1024, sizes)\n",
        "        self.drop_1 = nn.Dropout2d(p=0.3)\n",
        "\n",
        "        self.up_1 = PSPUpsample(1024, 256)\n",
        "        self.up_2 = PSPUpsample(256, 64)\n",
        "        self.up_3 = PSPUpsample(64, 64)\n",
        "\n",
        "        self.drop_2 = nn.Dropout2d(p=0.15)\n",
        "        self.final = nn.Sequential(\n",
        "            nn.Conv2d(64, n_classes, kernel_size=1),\n",
        "            nn.LogSoftmax()\n",
        "        )\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(deep_features_size, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(256, n_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        f, class_f = self.feats(x) \n",
        "        p = self.psp(f)\n",
        "        p = self.drop_1(p)\n",
        "\n",
        "        p = self.up_1(p)\n",
        "        p = self.drop_2(p)\n",
        "\n",
        "        p = self.up_2(p)\n",
        "        p = self.drop_2(p)\n",
        "\n",
        "        p = self.up_3(p)\n",
        "        p = self.drop_2(p)\n",
        "\n",
        "        auxiliary = F.adaptive_max_pool2d(input=class_f, output_size=(1, 1)).view(-1, class_f.size(1))\n",
        "\n",
        "        return self.final(p), self.classifier(auxiliary)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SRiZAHGsQxi4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "milestones = [15, 30, 45]\n",
        "\n",
        "net = PSPNet(n_classes=4, sizes=(1, 2, 3, 6), psp_size=2048, deep_features_size=1024, backend='resnet50')\n",
        "net = net.to(device)\n",
        "\n",
        "criterion = nn.NLLLoss(ignore_index=-1)\n",
        "# cls_criterion = nn.BCEWithLogitsLoss(weight=class_weights)\n",
        "optimizer = optim.Adam(net.parameters(), lr=1e-2, weight_decay=1e-4)\n",
        "scheduler = MultiStepLR(optimizer, milestones=[int(x) for x in milestones.split(',')])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QpzGJjANNg8h",
        "colab_type": "text"
      },
      "source": [
        "## Training and Validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "skvxCUzGNg8l",
        "colab_type": "code",
        "outputId": "662be056-a7c0-486f-c298-6e901d2e6d40",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "best_loss = float('inf')\n",
        "print('Training Started...')\n",
        "for epoch in range(num_epochs):\n",
        "    for phase in phases:\n",
        "        running_loss = 0.0\n",
        "        meter = Meter(phase, epoch)\n",
        "        start = time.strftime(\"%H:%M:%S\")\n",
        "        \n",
        "        print(f\"Starting epoch: {epoch} | phase: {phase} | ⏰: {start}\")\n",
        "        \n",
        "        # Each epoch has a training and validation phase\n",
        "        if phase==\"train\":\n",
        "            net.train()\n",
        "        else:\n",
        "            net.eval()\n",
        "        \n",
        "        #\n",
        "        net.zero_grad()\n",
        "        for itr, batch in enumerate(dataloaders[phase]):\n",
        "            images, masks = batch\n",
        "            images = images.to(device)\n",
        "            masks = masks.to(device)\n",
        "            \n",
        "            # forward\n",
        "            # track history if only in train\n",
        "            with torch.set_grad_enabled(phase=='train'):\n",
        "                outputs = net_decoder(net_encoder(images))\n",
        "                print(f'encoder:{net_encoder(images).shape}, decoder:{net_decoder(net_encoder(images)).shape}')\n",
        "                loss = criterion(masks, outputs)\n",
        "                loss /= accumulation_steps\n",
        "\n",
        "                if phase=='train':\n",
        "                    loss.backward()\n",
        "                    if (itr+1)%accumulation_steps == 0:\n",
        "                        encoder_optimizer.step()\n",
        "                        net.zero_grad()\n",
        "            \n",
        "            running_loss += loss.item()\n",
        "            outputs = outputs.detach().cpu()\n",
        "            meter.update(masks.cpu(), outputs)\n",
        "    \n",
        "        epoch_loss = (running_loss * accumulation_steps) / total_batches\n",
        "        dice, iou = epoch_log(phase, epoch, epoch_loss, meter, start)\n",
        "        losses[phase].append(epoch_loss)\n",
        "        dice_scores[phase].append(dice)\n",
        "        iou_scores[phase].append(iou)\n",
        "        torch.cuda.empty_cache()\n",
        "        \n",
        "        state = {\n",
        "            \"epoch\": epoch,\n",
        "            \"best_loss\": best_loss,\n",
        "            \"encoder_state_dict\": net_encoder.state_dict(),\n",
        "            \"decoder_state_dict\": net_decoder.state_dict(),\n",
        "            \"encoder_optimizer\": encoder_optimizer.state_dict(),\n",
        "            \"decoder_optimizer\": decoder_optimizer.state_dict()\n",
        "        }\n",
        "        \n",
        "        if phase=='valid':\n",
        "            encoder_scheduler.step(epoch_loss)\n",
        "            decoder_scheduler.step(epoch_loss)\n",
        "            if epoch_loss < best_loss:\n",
        "                print(\"******** New optimal found, saving state ********\")\n",
        "                state[\"best_loss\"] = best_loss = val_epoch\n",
        "                torch.save(state, f\"./model_{epoch}_{start}.pth\")\n",
        "    print() "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training Started...\n",
            "Starting epoch: 0 | phase: train | ⏰: 09:51:06\n",
            "torch.Size([4, 256, 256]) torch.Size([3, 256, 256])\n",
            "torch.Size([4, 256, 256]) torch.Size([3, 256, 256])\n",
            "torch.Size([4, 256, 256]) torch.Size([3, 256, 256])\n",
            "torch.Size([4, 256, 256]) torch.Size([3, 256, 256])\n",
            "torch.Size([4, 256, 256]) torch.Size([3, 256, 256])\n",
            "torch.Size([4, 256, 256]) torch.Size([3, 256, 256])\n",
            "torch.Size([4, 256, 256]) torch.Size([3, 256, 256])\n",
            "torch.Size([4, 256, 256]) torch.Size([3, 256, 256])\n",
            "torch.Size([4, 256, 256]) torch.Size([3, 256, 256])\n",
            "torch.Size([4, 256, 256]) torch.Size([3, 256, 256])\n",
            "torch.Size([4, 256, 256]) torch.Size([3, 256, 256])\n",
            "torch.Size([4, 256, 256]) torch.Size([3, 256, 256])\n",
            "torch.Size([4, 256, 256]) torch.Size([3, 256, 256])\n",
            "torch.Size([4, 256, 256]) torch.Size([3, 256, 256])\n",
            "torch.Size([4, 256, 256]) torch.Size([3, 256, 256])\n",
            "torch.Size([4, 256, 256]) torch.Size([3, 256, 256])\n",
            "torch.Size([4, 256, 256]) torch.Size([3, 256, 256])\n",
            "torch.Size([4, 256, 256]) torch.Size([3, 256, 256])\n",
            "torch.Size([4, 256, 256]) torch.Size([3, 256, 256])\n",
            "torch.Size([4, 256, 256]) torch.Size([3, 256, 256])\n",
            "torch.Size([4, 256, 256]) torch.Size([3, 256, 256])\n",
            "torch.Size([4, 256, 256]) torch.Size([3, 256, 256])\n",
            "torch.Size([4, 256, 256]) torch.Size([3, 256, 256])\n",
            "torch.Size([4, 256, 256]) torch.Size([3, 256, 256])\n",
            "torch.Size([4, 256, 256]) torch.Size([3, 256, 256])\n",
            "torch.Size([4, 256, 256]) torch.Size([3, 256, 256])\n",
            "torch.Size([4, 256, 256]) torch.Size([3, 256, 256])\n",
            "torch.Size([4, 256, 256]) torch.Size([3, 256, 256])\n",
            "torch.Size([4, 256, 256]) torch.Size([3, 256, 256])\n",
            "torch.Size([4, 256, 256]) torch.Size([3, 256, 256])\n",
            "torch.Size([4, 256, 256]) torch.Size([3, 256, 256])\n",
            "torch.Size([4, 256, 256]) torch.Size([3, 256, 256])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-63-01f214361c9d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0;31m# track history if only in train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_grad_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mphase\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m                 \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msegmentation_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0maccumulation_steps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-57-8ef9c98527c6>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, feed_dict, segSize)\u001b[0m\n\u001b[1;32m     26\u001b[0m                 \u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_deepsup\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'img_data'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_feature_maps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m                 \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'img_data'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_feature_maps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcrit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'seg_label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: list indices must be integers or slices, not str"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6cjSlHXqNg8w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# class Trainer(object):\n",
        "#     '''This class takes care of training and validation of our model'''\n",
        "#     def __init__(self, model):\n",
        "#         self.best_loss = float(\"inf\")\n",
        "#         self.phases = [\"train\", \"val\"]\n",
        "#         self.net = model \n",
        "#         self.net = self.net.to(self.device)\n",
        "#         cudnn.benchmark = True\n",
        "#         self.dataloaders = {\n",
        "#             phase: provider(\n",
        "#                 data_folder=data_folder,\n",
        "#                 df_path=train_df_path,\n",
        "#                 phase=phase,\n",
        "#                 mean=(0.485, 0.456, 0.406),\n",
        "#                 std=(0.229, 0.224, 0.225),\n",
        "#                 batch_size=self.batch_size[phase],\n",
        "#                 num_workers=self.num_workers,\n",
        "#             )\n",
        "#             for phase in self.phases\n",
        "#         }\n",
        "#         self.losses = {phase: [] for phase in self.phases}\n",
        "#         self.iou_scores = {phase: [] for phase in self.phases}\n",
        "#         self.dice_scores = {phase: [] for phase in self.phases}\n",
        "        \n",
        "#     def forward(self, images, targets):\n",
        "#         images = images.to(self.device)\n",
        "#         masks = targets.to(self.device)\n",
        "#         outputs = self.net(images)\n",
        "#         loss = self.criterion(outputs, masks)\n",
        "#         return loss, outputs\n",
        "\n",
        "#     def iterate(self, epoch, phase):\n",
        "#         meter = Meter(phase, epoch)\n",
        "#         start = time.strftime(\"%H:%M:%S\")\n",
        "#         print(f\"Starting epoch: {epoch} | phase: {phase} | ⏰: {start}\")\n",
        "#         batch_size = self.batch_size[phase]\n",
        "#         self.net.train(phase == \"train\")\n",
        "#         dataloader = self.dataloaders[phase]\n",
        "#         running_loss = 0.0\n",
        "#         total_batches = len(dataloader)\n",
        "# #         tk0 = tqdm(dataloader, total=total_batches)\n",
        "#         self.optimizer.zero_grad()\n",
        "#         for itr, batch in enumerate(dataloader): # replace `dataloader` with `tk0` for tqdm\n",
        "#             images, targets = batch\n",
        "#             loss, outputs = self.forward(images, targets)\n",
        "#             loss = loss / self.accumulation_steps\n",
        "#             if phase == \"train\":\n",
        "#                 loss.backward()\n",
        "#                 if (itr + 1 ) % self.accumulation_steps == 0:\n",
        "#                     self.optimizer.step()\n",
        "#                     self.optimizer.zero_grad()\n",
        "#             running_loss += loss.item()\n",
        "#             outputs = outputs.detach().cpu()\n",
        "#             meter.update(targets, outputs)\n",
        "# #             tk0.set_postfix(loss=(running_loss / ((itr + 1))))\n",
        "#         epoch_loss = (running_loss * self.accumulation_steps) / total_batches\n",
        "#         dice, iou = epoch_log(phase, epoch, epoch_loss, meter, start)\n",
        "#         self.losses[phase].append(epoch_loss)\n",
        "#         self.dice_scores[phase].append(dice)\n",
        "#         self.iou_scores[phase].append(iou)\n",
        "#         torch.cuda.empty_cache()\n",
        "#         return epoch_loss\n",
        "\n",
        "#     def start(self):\n",
        "#         for epoch in range(self.num_epochs):\n",
        "#             self.iterate(epoch, \"train\")\n",
        "#             state = {\n",
        "#                 \"epoch\": epoch,\n",
        "#                 \"best_loss\": self.best_loss,\n",
        "#                 \"state_dict\": self.net.state_dict(),\n",
        "#                 \"optimizer\": self.optimizer.state_dict(),\n",
        "#             }\n",
        "#             with torch.no_grad():\n",
        "#                 val_loss = self.iterate(epoch, \"val\")\n",
        "#                 self.scheduler.step(val_loss)\n",
        "#             if val_loss < self.best_loss:\n",
        "#                 print(\"******** New optimal found, saving state ********\")\n",
        "#                 state[\"best_loss\"] = self.best_loss = val_loss\n",
        "#                 torch.save(state, \"./model.pth\")\n",
        "#             print()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kHyx3fb8Ng87",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# model_trainer = Trainer(model)\n",
        "# model_trainer.start()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "deinENC1Ng9F",
        "colab_type": "text"
      },
      "source": [
        "## Plotting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dT3_wzuzNg9H",
        "colab_type": "code",
        "outputId": "3b76ad6e-d5a1-472d-9914-316043019fa5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 358
        }
      },
      "source": [
        "# PLOT TRAINING\n",
        "# losses = model_trainer.losses\n",
        "# dice_scores = model_trainer.dice_scores # overall dice\n",
        "# iou_scores = model_trainer.iou_scores\n",
        "\n",
        "def plot(scores, name):\n",
        "    plt.figure(figsize=(15,5))\n",
        "    plt.plot(range(len(scores[\"train\"])), scores[\"train\"], label=f'train {name}')\n",
        "    plt.plot(range(len(scores[\"train\"])), scores[\"val\"], label=f'val {name}')\n",
        "    plt.title(f'{name} plot'); plt.xlabel('Epoch'); plt.ylabel(f'{name}');\n",
        "    plt.legend(); \n",
        "    plt.show()\n",
        "\n",
        "plot(losses, \"BCE loss\")\n",
        "plot(dice_scores, \"Dice score\")\n",
        "plot(iou_scores, \"IoU score\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-73-2de6e8f8f00f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"BCE loss\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdice_scores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Dice score\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miou_scores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"IoU score\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-73-2de6e8f8f00f>\u001b[0m in \u001b[0;36mplot\u001b[0;34m(scores, name)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"train\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"train\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mf'train {name}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"train\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"val\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mf'val {name}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PRjGVOvdNg9U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}